@article{陈_李_2022,
  title    = {对话情绪识别综述},
  volume   = {59},
  number   = {3},
  journal  = {计算机工程与应用},
  author   = {陈晓婷 and 李实},
  year     = {2022},
  month    = {Oct},
  pages    = {33–48},
  language = {zh-CN}
}

@article{yan_yang_yin_2023,
  author  = {严豫 and 杨笛 and 尹德春},
  title   = {融合大语言模型知识的对比提示情感分析方法},
  journal = {情报杂志},
  volume  = {42},
  number  = {11},
  pages   = {126-134},
  year    = {2023},
  issn    = {1002-1965}
}

@article{Zheng_Liu_Yin_2021,
  author         = {Zheng, Wenfeng and Liu, Xiangjun and Yin, Lirong},
  title          = {Sentence Representation Method Based on Multi-Layer Semantic Network},
  journal        = {Applied Sciences},
  volume         = {11},
  year           = {2021},
  number         = {3},
  article-number = {1316},
  issn           = {2076-3417}
}

@article{罗_冉_杨_豆_2022,
  title    = {语音情感识别研究综述},
  volume   = {58},
  number   = {21},
  journal  = {计算机工程与应用},
  author   = {罗德虎 and 冉启武 and 杨超 and 豆旺},
  year     = {2022},
  month    = {Jul},
  pages    = {40–52},
  language = {zh-CN}
}

@article{丁_陈_曾_2023,
  author  = {丁美荣 and 陈鸿业 and 曾碧卿},
  title   = {跨模态语义对齐和信息细化的多模态情感分析},
  journal = {计算机工程与应用},
  volume  = {60},
  number  = {22},
  pages   = {114-125},
  year    = {2024},
  issn    = {1002-8331}
}

@article{Plutchik_1982,
  title    = {A psychoevolutionary theory of Emotions},
  journal  = {Social Science Information},
  author   = {Plutchik, Robert},
  year     = {1982},
  month    = {Jul},
  volume   = {21},
  number   = {4-5},
  pages    = {529–553},
  language = {en-US}
}

@article{Ekman_1993,
  title    = {Facial expression and emotion},
  journal  = {American Psychologist},
  author   = {Ekman, Paul},
  year     = {1993},
  month    = {Apr},
  language = {en-US},
  volume   = {48},
  number   = {4},
  pages    = {384–392}
}

@inproceedings{Rozgic_Ananthakrishnan_Saleem_Kumar_Prasad_2012,
  author    = {Rozgić, Viktor and Ananthakrishnan, Sankaranarayanan and Saleem, Shirin and Kumar, Rohit and Prasad, Rohit},
  booktitle = {Asia Pacific Signal and Information Processing Association Annual Summit and Conference},
  title     = {Ensemble of SVM trees for multimodal emotion recognition},
  year      = {2012},
  volume    = {},
  number    = {},
  pages     = {1-4},
  keywords  = {Feature extraction;Support vector machines;Acoustics;Accuracy;Emotion recognition;Vectors;Visualization}
}

@inproceedings{Jin_Li_Chen_Wu_2015,
  author    = {Jin, Qin and Li, Chengxin and Chen, Shizhe and Wu, Huimin},
  booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing},
  title     = {Speech emotion recognition with acoustic and lexical features},
  year      = {2015},
  volume    = {},
  number    = {},
  pages     = {4749-4753},
  keywords  = {Acoustics;Feature extraction;Emotion recognition;Speech;Accuracy;Speech recognition;Support vector machines;Emotion recognition;Acoustic features;Emotion lexicon;Lexical features;Support vector machine}
}

@inproceedings{Zeng_Hu_Liu_Fu_Huang_2006,
  author    = {Zeng, Zhihong and Hu, Yuxiao and Liu, Ming and Fu, Yun and Huang, Thomas S.},
  title     = {Training combination strategy of multi-stream fused hidden Markov model for audio-visual affect recognition},
  year      = {2006},
  isbn      = {1595934472},
  booktitle = {ACM International Conference on Multimedia},
  pages     = {65–68},
  numpages  = {4}
}

@inproceedings{Glodek_Reuter_Schels_Dietmayer_Schwenker_2013,
  author    = {Glodek, Michael and Reuter, Stephan and Schels, Martin and Dietmayer, Klaus and Schwenker, Friedhelm},
  title     = {Kalman Filter Based Classifier Fusion for Affective State Recognition},
  booktitle = {Multiple Classifier Systems},
  year      = {2013},
  pages     = {85--94},
  isbn      = {978-3-642-38067-9}
}

@article{Kessous_Castellano_Caridakis_2010,
  title    = {Multimodal emotion recognition in speech-based interaction using facial expression, body gesture and acoustic analysis},
  journal  = {Journal on Multimodal User Interfaces},
  author   = {Kessous, Loic and Castellano, Ginevra and Caridakis, George},
  year     = {2010},
  month    = {Mar},
  volume   = {3},
  number   = {1},
  pages    = {33–48},
  language = {en-US}
}

@inproceedings{Bertero_Siddique_Wu_Wan_Chan_Fung_2016,
  title     = {Real-Time Speech Emotion and Sentiment Recognition for Interactive Dialogue Systems},
  author    = {Bertero, Dario  and Siddique, Farhad Bin  and Wu, Chien-Sheng  and Wan, Yan  and Chan, Ricky Ho Yin  and Fung, Pascale},
  booktitle = {Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2016},
  publisher = {Association for Computational Linguistics},
  pages     = {1042--1047}
}

@inproceedings{Poria_Cambria_Hazarika_Majumder_Zadeh_Morency_2017,
  title     = {Context-Dependent Sentiment Analysis in User-Generated Videos},
  author    = {Poria, Soujanya  and Cambria, Erik  and Hazarika, Devamanyu  and Majumder, Navonil  and Zadeh, Amir  and Morency, Louis-Philippe},
  booktitle = {Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2017},
  address   = {Vancouver, Canada},
  pages     = {873--883},
  volume    = {1}
}

@article{Hochreiter_Schmidhuber_1997,
  author  = {Hochreiter, Sepp and Schmidhuber, Jürgen},
  journal = {Neural Computation},
  title   = {Long Short-Term Memory},
  year    = {1997},
  volume  = {9},
  number  = {8},
  pages   = {1735-1780}
}


@article{Jiao_Yang_King_Lyu_2019,
  title     = {HiGRU: Hierarchical Gated Recurrent Units for Utterance-Level Emotion Recognition},
  author    = {Jiao, Wenxiang and Yang, Haiqin and King, Irwin and Lyu, Michael R},
  booktitle = {Conference of the North American Chapter 
               of the Association for Computational Linguistics: 
               Human Language Technologies},
  pages     = {397-406},
  year      = {2019},
  volume    = {1}
}

@inproceedings{Cho_van_Merrienboer_Gulcehre_Bahdanau_Bougares_Schwenk_Bengio_2014,
  title     = {Learning Phrase Representations using {RNN} Encoder{--}Decoder for Statistical Machine Translation},
  author    = {Cho, Kyunghyun  and
               van Merri{\"e}nboer, Bart  and
               Gulcehre, Caglar  and
               Bahdanau, Dzmitry  and
               Bougares, Fethi  and
               Schwenk, Holger  and
               Bengio, Yoshua},
  booktitle = {Conference on Empirical Methods in Natural Language Processing},
  month     = oct,
  year      = {2014},
  pages     = {1724--1734}
}

@article{Chen_Hsu_Kuo_Ting-Hao_Huang_Ku_2018,
  title     = {{E}motion{L}ines: An Emotion Corpus of Multi-Party Conversations},
  author    = {Hsu, Chao-Chun  and
               Chen, Sheng-Yeh  and
               Kuo, Chuan-Chun  and
               Huang, Ting-Hao  and
               Ku, Lun-Wei},
  booktitle = {International Conference on Language Resources and Evaluation},
  month     = may,
  year      = {2018}
}

@article{Elman_1990,
  title    = {Finding Structure in Time},
  journal  = {Cognitive Science},
  author   = {Elman, Jeffrey L.},
  year     = {1990},
  month    = {Mar},
  volume   = {14},
  number   = {2},
  pages    = {179–211},
  language = {en-US}
}

@article{Vaswani_Shazeer_Parmar_Uszkoreit_Jones_Gomez_Kaiser_Polosukhin_2017,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {},
  title     = {Attention is All you Need},
  volume    = {30},
  year      = {2017}
}

@inproceedings{Devlin_Chang_Lee_Toutanova_2019,
  title     = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author    = {Devlin, Jacob  and
               Chang, Ming-Wei  and
               Lee, Kenton  and
               Toutanova, Kristina},
  booktitle = {Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month     = jun,
  volume    = {1},
  year      = {2019},
  pages     = {4171--4186}
}

@article{Radford_Narasimhan_Salimans_Sutskever,
  title    = {Improving Language Understanding by Generative Pre-Training},
  author   = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  language = {en-US},
  year     = {2018}
}

@article{Yingjian_Jiang_Xiaoping_Zhigang_2023,
  title    = {EmotionIC: Emotional Inertia and Contagion-driven Dependency Modelling for Emotion Recognition in Conversation},
  author   = {Yingjian, Liu and Jiang, Li and Xiaoping, Wang and Zhigang, Zeng},
  journal  = {Science China Information Sciences},
  year     = {2024},
  volume   = {67},
  language = {en-US}
}

@article{Hu_Bao_Wei_Zhou_Hu_2023,
  title     = {Supervised Adversarial Contrastive Learning for Emotion Recognition in Conversations},
  author    = {Hu, Dou  and
               Bao, Yinan  and
               Wei, Lingwei  and
               Zhou, Wei  and
               Hu, Songlin},
  booktitle = {Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2023},
  volume    = {1},
  pages     = {10835--10852}
}

@inproceedings{Hu_Wei_Huai_2021,
  title     = {{D}ialogue{CRN}: Contextual Reasoning Networks for Emotion Recognition in Conversations},
  author    = {Hu, Dou  and
               Wei, Lingwei  and
               Huai, Xiaoyong},
  booktitle = {Annual Meeting of the Association for Computational Linguistics and International Joint Conference on Natural Language Processing},
  month     = aug,
  year      = {2021},
  volume    = {1},
  pages     = {7042--7052}
}

@inproceedings{Ghosal_Majumder_Gelbukh_Mihalcea_Poria_2020,
  title     = {{COSMIC}: {CO}mmon{S}ense knowledge for e{M}otion Identification in Conversations},
  author    = {Ghosal, Deepanway  and
               Majumder, Navonil  and
               Gelbukh, Alexander  and
               Mihalcea, Rada  and
               Poria, Soujanya},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP},
  month     = nov,
  year      = {2020},
  pages     = {2470--2481},
  abstract  = {In this paper, we address the task of utterance level emotion recognition in conversations using commonsense knowledge. We propose COSMIC, a new framework that incorporates different elements of commonsense such as mental states, events, and causal relations, and build upon them to learn interactions between interlocutors participating in a conversation. Current state-of-theart methods often encounter difficulties in context propagation, emotion shift detection, and differentiating between related emotion classes. By learning distinct commonsense representations, COSMIC addresses these challenges and achieves new state-of-the-art results for emotion recognition on four different benchmark conversational datasets. Our code is available at \url{https://github.com/declare-lab/conv-emotion}.}
}

@inproceedings{Li_Lin_Fu_Wang_2021,
  title     = {Past, Present, and Future: Conversational Emotion Recognition through Structural Modeling of Psychological Knowledge},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP},
  author    = {Li, Jiangnan and Lin, Zheng and Fu, Peng and Wang, Weiping},
  year      = {2021},
  month     = {Jan},
  pages     = {1204--1214},
  language  = {en-US}
}

@inproceedings{Liang_Yang_Xu_Huang_Wang_Dong,
  title     = {{S}+{PAGE}: A Speaker and Position-Aware Graph Neural Network Model for Emotion Recognition in Conversation},
  author    = {Liang, Chen  and
               Xu, Jing  and
               Lin, Yangkun  and
               Yang, Chong  and
               Wang, Yongliang},
  booktitle = {Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and International Joint Conference on Natural Language Processing},
  month     = nov,
  year      = {2022},
  pages     = {148--157},
  volume    = {1},
  abstract  = {Emotion recognition in conversation (ERC) has attracted much attention in recent years for its necessity in widespread applications. With the development of graph neural network (GNN), recent state-of-the-art ERC models mostly use GNN to embed the intrinsic structure information of a conversation into the utterance features. In this paper, we propose a novel GNN-based model for ERC, namely S+PAGE, to better capture the speaker and position-aware conversation structure information. Specifically, we add the relative positional encoding and speaker dependency encoding in the representations of edge weights and edge types respectively to acquire a more reasonable aggregation algorithm for ERC. Besides, a two-stream conversational Transformer is presented to extract both the self and inter-speaker contextual features for each utterance. Extensive experiments are conducted on four ERC benchmarks with state-of-the-art models employed as baselines for comparison, whose results demonstrate the superiority of our model.}
}

@inproceedings{Shen_Wu_Yang_Quan_2021,
  title     = {Directed Acyclic Graph Network for Conversational Emotion Recognition},
  booktitle = {Annual Meeting of the Association for Computational Linguistics and International Joint Conference on Natural Language Processing},
  author    = {Shen, Weizhou and Wu, Siyue and Yang, Yunyi and Quan, Xiaojun},
  year      = {2021},
  month     = {Jan},
  pages     = {1204--1214},
  volume    = {1},
  language  = {en-US}
}

@article{Poria_Cambria_Bajpai_Hussain,
  title    = {A review of affective computing: From unimodal analysis to multimodal fusion},
  journal  = {Information Fusion},
  volume   = {37},
  pages    = {98-125},
  year     = {2017},
  issn     = {1566-2535},
  author   = {Soujanya Poria and Erik Cambria and Rajiv Bajpai and Amir Hussain},
  keywords = {Affective computing, Sentiment analysis, Multimodal affect analysis, Multimodal fusion, Audio, visual and text information fusion}
}

@article{Colby_Ortony_Clore_Collins_1989,
  title    = {The Cognitive Structure of Emotions.},
  volume   = {18},
  number   = {6},
  journal  = {Contemporary Sociology},
  author   = {Colby, B. N. and Ortony, Andrew and Clore, Gerald L. and Collins, Allan},
  year     = {1989},
  month    = {Nov},
  pages    = {957},
  language = {en-US}
}

@article{Rogers,
  title    = {Client-Centered Therapy: Its Current Practice, Implications and Theory},
  author   = {Rogers, CarlR.},
  year     = {1951},
  language = {en-US}
}

@article{Kazdin_Blase_2011,
  title    = {Rebooting Psychotherapy Research and Practice to Reduce the Burden of Mental Illness},
  volume   = {6},
  number   = {1},
  journal  = {Perspectives on Psychological Science},
  author   = {Kazdin, Alan E. and Blase, Stacey L.},
  year     = {2011},
  month    = {Jan},
  pages    = {21–37},
  language = {en-US}
}

@article{Fitzpatrick_Darcy_Vierhile_2017,
  title    = {Delivering Cognitive Behavior Therapy to Young Adults With Symptoms of Depression and Anxiety Using a Fully Automated Conversational Agent (Woebot): A Randomized Controlled Trial},
  journal  = {JMIR Mental Health},
  author   = {Fitzpatrick, Kathleen Kara and Darcy, Alison and Vierhile, Molly},
  year     = {2017},
  month    = {Jun},
  volume   = {4},
  number   = {2},
  pages    = {e19},
  language = {en-US}
}

@inproceedings{Shen_Rudzicz_2017,
  title     = {Detecting Anxiety through {R}eddit},
  author    = {Shen, Judy Hanwen  and
               Rudzicz, Frank},
  booktitle = {Workshop on Computational Linguistics and Clinical Psychology {---} From Linguistic Signal to Clinical Reality},
  month     = aug,
  year      = {2017},
  pages     = {58--65},
  abstract  = {Previous investigations into detecting mental illnesses through social media have predominately focused on detecting depression through Twitter corpora. In this paper, we study anxiety disorders through personal narratives collected through the popular social media website, Reddit. We build a substantial data set of typical and anxiety-related posts, and we apply N-gram language modeling, vector embeddings, topic analysis, and emotional norms to generate features that accurately classify posts related to binary levels of anxiety. We achieve an accuracy of 91{\%} with vector-space word embeddings, and an accuracy of 98{\%} when combined with lexicon-based features.}
}

@article{Williams_Andrews_2013,
  title    = {The Effectiveness of Internet Cognitive Behavioural Therapy (iCBT) for Depression in Primary Care: A Quality Assurance Study},
  volume   = {8},
  number   = {2},
  journal  = {PLoS ONE},
  author   = {Williams, Alishia D and Andrews, Gavin},
  year     = {2013},
  month    = {Feb},
  pages    = {e57447},
  language = {en-US}
}

@article{Guntuku_Yaden_Kern_Ungar_Eichstaedt_2017,
  title    = {Detecting depression and mental illness on social media: an integrative review},
  journal  = {Current Opinion in Behavioral Sciences},
  author   = {Guntuku, Sharath Chandra and Yaden, David B and Kern, Margaret L and Ungar, Lyle H and Eichstaedt, Johannes C},
  year     = {2017},
  month    = {Dec},
  volume   = {18},
  number   = {1},
  pages    = {43–49},
  language = {en-US}
}

@article{Chowdhery_Narang_Devlin_Bosma_Mishra_Roberts_Barham_Chung_Sutton_Gehrmann_etal,
  author    = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sashank and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
  title     = {PaLM: scaling language modeling with pathways},
  year      = {2023},
  volume    = {24},
  number    = {1},
  issn      = {1532-4435},
  abstract  = {Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540- billion parameter, densely activated, Transformer language model, which we call Pathways Language Model (PaLM).We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.},
  journal   = {J. Mach. Learn. Res.},
  month     = jan,
  articleno = {240},
  numpages  = {113},
  keywords  = {large language models, few-shot learning, natural language processing, scalable deep learning}
}

@misc{Bai_Bai_Chu_Cui_Dang_Deng_Fan_Ge_Han_Huang_et,
  title         = {Qwen Technical Report},
  author        = {Jinze Bai and Shuai Bai and Yunfei Chu and Zeyu Cui and Kai Dang and Xiaodong Deng and Yang Fan and Wenbin Ge and Yu Han and Fei Huang and Binyuan Hui and Luo Ji and Mei Li and Junyang Lin and Runji Lin and Dayiheng Liu and Gao Liu and Chengqiang Lu and Keming Lu and Jianxin Ma and Rui Men and Xingzhang Ren and Xuancheng Ren and Chuanqi Tan and Sinan Tan and Jianhong Tu and Peng Wang and Shijie Wang and Wei Wang and Shengguang Wu and Benfeng Xu and Jin Xu and An Yang and Hao Yang and Jian Yang and Shusheng Yang and Yang Yao and Bowen Yu and Hongyi Yuan and Zheng Yuan and Jianwei Zhang and Xingxuan Zhang and Yichang Zhang and Zhenru Zhang and Chang Zhou and Jingren Zhou and Xiaohuan Zhou and Tianhang Zhu},
  year          = {2023},
  eprint        = {2309.16609},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{Touvron_Lavril_Izacard_Martinet_Lachaux_Lacroix_Roziere_Goyal_Hambro_Azhar_et,
  title         = {LLaMA: Open and Efficient Foundation Language Models},
  author        = {Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
  year          = {2023},
  eprint        = {2302.13971},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{Xiong_Wang_Zhu_Zhao_Liu_Huang_Wang_Shen,
  title         = {DoctorGLM: Fine-tuning your Chinese Doctor is not a Herculean Task},
  author        = {Honglin Xiong and Sheng Wang and Yitao Zhu and Zihao Zhao and Yuxiao Liu and Linlin Huang and Qian Wang and Dinggang Shen},
  year          = {2023},
  eprint        = {2304.01097},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{Lai_Shi_Du_Wu_Fu_Dou_Wang_2023,
  title         = {Psy-LLM: Scaling up Global Mental Health Psychological Services with AI-based Large Language Models},
  author        = {Tin Lai and Yukun Shi and Zicong Du and Jiajie Wu and Ken Fu and Yichao Dou and Ziqi Wang},
  year          = {2023},
  eprint        = {2307.11991},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{yang2024emollmmultimodalemotionalunderstanding,
  title         = {EmoLLM: Multimodal Emotional Understanding Meets Large Language Models},
  author        = {Qu Yang and Mang Ye and Bo Du},
  year          = {2024},
  eprint        = {2406.16442},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{Zhang_He_Song_He_Zhang_Qiu_Li_Ma_Lan_2023,
  title         = {ConceptPsy:A Benchmark Suite with Conceptual Comprehensiveness in Psychology},
  author        = {Junlei Zhang and Hongliang He and Nirui Song and Zhanchao Zhou and Shuyuan He and Shuai Zhang and Huachuan Qiu and Anqi Li and Yong Dai and Lizhi Ma and Zhenzhong Lan},
  year          = {2024},
  eprint        = {2311.09861},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inproceedings{Chen_Xing_Lin_Zheng_Wang_Liu_Xu_2023,
  title     = {{S}oul{C}hat: Improving {LLM}s' Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations},
  author    = {Chen, Yirong  and
               Xing, Xiaofen  and
               Lin, Jingkai  and
               Zheng, Huimin  and
               Wang, Zhenyu  and
               Liu, Qi  and
               Xu, Xiangmin},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP},
  month     = dec,
  year      = {2023},
  pages     = {1170--1183},
  abstract  = {Large language models (LLMs) have been widely applied in various fields due to their excellent capability for memorizing knowledge and chain of thought (CoT). When these language models are applied in the field of psychological counseling, they often rush to provide universal advice. However, when users seek psychological support, they need to gain empathy, trust, understanding and comfort, rather than just reasonable advice. To this end, we constructed a multi-turn empathetic conversation dataset of more than 2 million samples, in which the input is the multi-turn conversation context, and the target is empathetic responses that cover expressions such as questioning, comfort, recognition, listening, trust, emotional support, etc. Experiments have shown that the empathy ability of LLMs can be significantly enhanced when finetuning by using multi-turn dialogue history and responses that are closer to the expression of a psychological consultant.}
}

@inproceedings{Qiu_He_Zhang_Li_Lan_2023,
  title     = {{SMILE}: Single-turn to Multi-turn Inclusive Language Expansion via {C}hat{GPT} for Mental Health Support},
  author    = {Qiu, Huachuan  and
               He, Hongliang  and
               Zhang, Shuai  and
               Li, Anqi  and
               Lan, Zhenzhong},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP},
  month     = nov,
  year      = {2024},
  pages     = {615--636},
  abstract  = {Developing specialized dialogue systems for mental health support requires multi-turn conversation data, which has recently garnered increasing attention. However, gathering and releasing large-scale, real-life multi-turn conversations that could facilitate advancements in mental health support presents challenges in data privacy protection and the time and cost involved in crowdsourcing. To address these challenges, we introduce SMILE, a single-turn to multi-turn inclusive language expansion technique that prompts ChatGPT to rewrite public single-turn dialogues into multi-turn ones. Our work begins by analyzing language transformation and validating the feasibility of our proposed method. We conduct a study on dialogue diversity, including lexical features, semantic features, and dialogue topics, demonstrating the effectiveness of our method. Further, we employ our method to generate a large-scale, lifelike, and diverse dialogue dataset named SMILECHAT, consisting of 55k dialogues. Finally, we utilize the collected corpus to develop a mental health chatbot, MeChat. To better assess the quality of SMILECHAT, we collect a small-scale real-life counseling dataset conducted by data anonymization. Both automatic and human evaluations demonstrate significant improvements in our dialogue system and confirm that SMILECHAT is high-quality. Code, data, and model are publicly available at https://github.com/qiuhuachuan/smile.}
}

@misc{Achiam_Adler_Agarwal_Ahmad_Akkaya_Aleman_Almeida_Altenschmidt_Altman_Anadkat_et,
  title         = {GPT-4 Technical Report},
  author        = {OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
  year          = {2024},
  eprint        = {2303.08774},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@article{El_Ayadi_Kamel_Karray_2011,
  title    = {Survey on speech emotion recognition: Features, classification schemes, and databases},
  journal  = {Pattern Recognition},
  author   = {El Ayadi, Moataz and Kamel, Mohamed S. and Karray, Fakhri},
  year     = {2011},
  month    = {Mar},
  volume   = {44},
  number   = {3},
  pages    = {572–587},
  language = {en-US}
}

@article{Nwe_Foo_De_Silva_2003,
  title    = {Speech emotion recognition using hidden Markov models},
  journal  = {Speech Communication},
  author   = {Nwe, Tin Lay and Foo, Say Wei and De Silva, Liyanage C},
  year     = {2003},
  month    = {Nov},
  volume   = {41},
  number   = {4},
  pages    = {603–623},
  language = {en-US}
}

@article{Jiang_Fu_Tao_Lei_Zhao_2019,
  title    = {Parallelized Convolutional Recurrent Neural Network With Spectral Features for Speech Emotion Recognition},
  journal  = {IEEE Access},
  author   = {Jiang, Pengxu and Fu, Hongliang and Tao, Huawei and Lei, Peizhi and Zhao, Li},
  year     = {2019},
  month    = {Jan},
  volume   = {7},
  number   = {1},
  pages    = {90368–90377},
  language = {en-US}
}

@inproceedings{Ye_Wang_Yang_Zou_2021,
  title     = {Improving the Performance of Automated Audio Captioning via Integrating the Acoustic and Semantic Information},
  booktitle = {Workshop on Detection and Classification of Acoustic Scenes and Events},
  author    = {Ye, Zhongjie and Wang, Helin and Yang, Dongchao and Zou, Yuexian},
  year      = {2021},
  month     = {Oct},
  language  = {en-US}
}

@inproceedings{xu2024secap,
  title     = {Secap: Speech emotion captioning with large language model},
  author    = {Xu, Yaoxun and Chen, Hangting and Yu, Jianwei and Huang, Qiaochu and Wu, Zhiyong and Zhang, Shi-Xiong and Li, Guangzhi and Luo, Yi and Gu, Rongzhi},
  booktitle = {AAAI Conference on Artificial Intelligence},
  volume    = {38},
  number    = {17},
  pages     = {19323--19331},
  year      = {2024}
}

@inproceedings{Schneider_Baevski_Collobert_Auli_2019,
  title     = {wav2vec: Unsupervised Pre-Training for Speech Recognition},
  booktitle = {Interspeech},
  author    = {Schneider, Steffen and Baevski, Alexei and Collobert, Ronan and Auli, Michael},
  year      = {2019},
  month     = {Sep},
  pages     = {2207--2211},
  language  = {en-US}
}

@article{Hsu_Bolte_Tsai_Lakhotia_Salakhutdinov_Mohamed_2021,
  title    = {HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units},
  journal  = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  author   = {Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  year     = {2021},
  month    = {Jan},
  volume   = {29},
  pages    = {3451–3460},
  language = {en-US}
}

@article{Mei_Meng_Liu_Kong_Ko_Zhao_Plumbley_Zou_Wang,
  author   = {Mei, Xinhao and Meng, Chutong and Liu, Haohe and Kong, Qiuqiang and Ko, Tom and Zhao, Chengqi and Plumbley, Mark D. and Zou, Yuexian and Wang, Wenwu},
  journal  = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title    = {WavCaps: A ChatGPT-Assisted Weakly-Labelled Audio Captioning Dataset for Audio-Language Multimodal Research},
  year     = {2024},
  volume   = {32},
  number   = {},
  pages    = {3339-3354},
  keywords = {Task analysis;Chatbots;Noise measurement;Electronic mail;Speech processing;Pipelines;Engines;Audio-language dataset;multimodal learning;ChatGPT;deep learning}
}

@article{Chen_2022,
  title   = {WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing},
  volume  = {16},
  issn    = {1941-0484},
  number  = {6},
  journal = {IEEE Journal of Selected Topics in Signal Processing},
  author  = {Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and Wu, Jian and Zhou, Long and Ren, Shuo and Qian, Yanmin and Qian, Yao and Wu, Jian and Zeng, Michael and Yu, Xiangzhan and Wei, Furu},
  year    = {2022},
  month   = oct,
  pages   = {1505–1518}
}

@inbook{Zhang_Sennrich_2019,
  author    = {Zhang, Biao and Sennrich, Rico},
  title     = {Root mean square layer normalization},
  year      = {2019},
  publisher = {Curran Associates Inc.},
  abstract  = {Layer normalization (LayerNorm) has been successfully applied to various deep neural networks to help stabilize training and boost model convergence because of its capability in handling re-centering and re-scaling of both inputs and weight matrix. However, the computational overhead introduced by LayerNorm makes these improvements expensive and significantly slows the underlying network, e.g. RNN in particular. In this paper, we hypothesize that re-centering invariance in LayerNorm is dispensable and propose root mean square layer normalization, or RMSNorm. RMSNorm regularizes the summed inputs to a neuron in one layer according to root mean square (RMS), giving the model re-scaling invariance property and implicit learning rate adaptation ability. RMSNorm is computationally simpler and thus more efficient than LayerNorm. We also present partial RMSNorm, or pRMSNorm where the RMS is estimated from p\% of the summed inputs without breaking the above properties. Extensive experiments on several tasks using diverse network architectures show that RMSNorm achieves comparable performance against LayerNorm but reduces the running time by 7\%~64\% on different models. Source code is available at https://github.com/bzhangGo/rmsnorm.},
  booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
  articleno = {1110},
  numpages  = {12}
}

@misc{Ba_Kiros_Hinton_2016,
  title         = {Layer Normalization},
  author        = {Jimmy Lei Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
  year          = {2016},
  eprint        = {1607.06450},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML}
}

@article{Su_Lu_Pan_Wen_Liu_2021,
  author   = {Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  title    = {RoFormer: Enhanced transformer with Rotary Position Embedding},
  year     = {2024},
  volume   = {568},
  number   = {C},
  issn     = {0925-2312},
  journal  = {Neurocomput.},
  month    = feb,
  numpages = {12},
  keywords = {Pre-trained language models, Position information encoding, Pre-training, Natural language processing}
}

@misc{ainslie2023gqatraininggeneralizedmultiquery,
  title         = {GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints},
  author        = {Joshua Ainslie and James Lee-Thorp and Michiel de Jong and Yury Zemlyanskiy and Federico Lebrón and Sumit Sanghai},
  year          = {2023},
  eprint        = {2305.13245},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{Shazeer_2020,
  title         = {GLU Variants Improve Transformer},
  author        = {Noam Shazeer},
  year          = {2020},
  eprint        = {2002.05202},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@inproceedings{hu2022lora,
  title     = {Lo{RA}: Low-Rank Adaptation of Large Language Models},
  author    = {Edward J Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
  booktitle = {International Conference on Learning Representations},
  year      = {2022}
}

@inproceedings{kwon2023efficient,
  author    = {Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph and Zhang, Hao and Stoica, Ion},
  title     = {Efficient Memory Management for Large Language Model Serving with PagedAttention},
  year      = {2023},
  isbn      = {9798400702297},
  abstract  = {High throughput serving of large language models (LLMs) requires batching sufficiently many requests at a time. However, existing systems struggle because the key-value cache (KV cache) memory for each request is huge and grows and shrinks dynamically. When managed inefficiently, this memory can be significantly wasted by fragmentation and redundant duplication, limiting the batch size. To address this problem, we propose PagedAttention, an attention algorithm inspired by the classical virtual memory and paging techniques in operating systems. On top of it, we build vLLM, an LLM serving system that achieves (1) near-zero waste in KV cache memory and (2) flexible sharing of KV cache within and across requests to further reduce memory usage. Our evaluations show that vLLM improves the throughput of popular LLMs by 2--4\texttimes{} with the same level of latency compared to the state-of-the-art systems, such as FasterTransformer and Orca. The improvement is more pronounced with longer sequences, larger models, and more complex decoding algorithms. vLLM's source code is publicly available at https://github.com/vllm-project/vllm.},
  booktitle = {Proceedings of the 29th Symposium on Operating Systems Principles},
  pages     = {611–626},
  numpages  = {16}
}

@misc{zheng2024SGLangefficientexecutionstructured,
  title         = {SGLang: Efficient Execution of Structured Language Model Programs},
  author        = {Lianmin Zheng and Liangsheng Yin and Zhiqiang Xie and Chuyue Sun and Jeff Huang and Cody Hao Yu and Shiyi Cao and Christos Kozyrakis and Ion Stoica and Joseph E. Gonzalez and Clark Barrett and Ying Sheng},
  year          = {2024},
  eprint        = {2312.07104},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI}
}

@article{Busso_Bulut_Lee_Kazemzadeh_Mower_Kim_Chang_Lee_Narayanan_2008,
  title    = {IEMOCAP: interactive emotional dyadic motion capture database},
  journal  = {Language Resources and Evaluation},
  author   = {Busso, Carlos and Bulut, Murtaza and Lee, Chi-Chun and Kazemzadeh, Abe and Mower, Emily and Kim, Samuel and Chang, Jeannette N. and Lee, Sungbok and Narayanan, Shrikanth S.},
  year     = {2008},
  month    = {Dec},
  volume   = {42},
  number   = {4},
  pages    = {335–359},
  language = {en-US}
}

@inproceedings{Poria_Hazarika_Majumder_Naik_Cambria_Mihalcea_2019,
  title     = {MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations},
  booktitle = {Annual Meeting of the Association for Computational Linguistics},
  author    = {Poria, Soujanya and Hazarika, Devamanyu and Majumder, Navonil and Naik, Gautam and Cambria, Erik and Mihalcea, Rada},
  year      = {2019},
  month     = {Jan},
  pages     = {5278--5288},
  language  = {en-US}
}
